#+TITLE: README for the HDDA python toolbox
#+AUTHOR: Mathieu Fauvel
#+EMAIL: mathieu.fauvel@ensat.fr
#+EXCLUDE_TAGS: noexport
#+OPTIONS: toc:nil

* Objectives
The package provides a python implementation of the High Dimensional
Discriminant analysis/clustering models, see publications:
- [[http://hal.archives-ouvertes.fr/hal-00394327]]
- [[http://hal.archives-ouvertes.fr/hal-00022183/]]

  
The original =R= package available on the CRAN:
[[http://cran.r-project.org/web/packages/HDclassif/index.html]]

Some of the models are actually implemented, those who usually provide
the best results in terms of classification accuracy.

* Install and requirements
:PROPERTIES:
:session:  softwares
:exports:  both
:results: output raw
:END:
Just  download  the package.  It  has  been  tested on  linux,  Debian
Wheezy.  [[http://www.scipy.org/][Scipy]] and  [[http://scikit-learn.org/stable/][Scikit]] should  be  installed. Also,  for a  faster
processing, a good linear algebra library is preferable. [[http://openblas.net/][Openblas]] is a
good option.

#+BEGIN_SRC python
import platform
platform.python_version()
#+END_SRC

#+RESULTS:

'2.7.9'

#+BEGIN_SRC python
import scipy as sp
sp.__version__
#+END_SRC

#+RESULTS:

'0.14.0'

#+BEGIN_SRC python 
import sklearn
sklearn.__version__
#+END_SRC

#+RESULTS:

'0.17.1'

* Usage
** Crabs data set
:PROPERTIES:
:tangle:   script_crabs.py
:noweb:    yes
:exports:  both
:session:  hdda
:results:  output
:END:

We provide an introductory example taken from Charles Bouveyron
thesis, on the /crabs/ data set. We also compare with the standard GMM
with EM provided by scikit.

First, load packages and define some variables:
#+BEGIN_SRC python 
import hdda
import matplotlib.pyplot as plt
import scipy as sp
from sklearn.decomposition import PCA
from sklearn import mixture

# Parameters for HDDA
MODEL = ['M1','M2','M3','M4','M5','M6','M7','M8']
C = [4] # For the example with do not fit the number of classes
th = [0.05,0.1,0.2] # The threshold for the Cattel test
#+END_SRC

#+RESULTS:

Load the data

#+BEGIN_SRC python 
data = sp.load('crabs.npz')
X = data['x']
Y = data['y']
#+END_SRC

#+RESULTS:

For illustration, we can plot the projection on the two first PC axis.

#+BEGIN_SRC python 
plt.figure()
pca = PCA(n_components=2)
Xp = pca.fit_transform(X)
plt.scatter(Xp[:,0],Xp[:,1],c=Y,s=40)
plt.savefig('2D_true_labels.png')
#+END_SRC

#+RESULTS:

[[file:2D_true_labels.png]]

Then  we learn  each model  and store  the optimal  BIC value  and its
corresponding  parameters.  It  can  be done  automatically  with  the
=fit_all= method.

#+BEGIN_SRC python
model = hdda.HDGMM()
model.fit_all(X,MODEL=MODEL,C=C,th=th,VERBOSE=True)
#+END_SRC

#+RESULTS:

#+begin_example

Models 	 C 	 th 	 BIC
M1 	 4 	 0.05 	 -2809.07919719
M2 	 4 	 0.05 	 -2793.18425379
M3 	 4 	 0.1 	 -2815.45170855
M4 	 4 	 0.05 	 -2799.55676218
M5 	 4 	 0.2 	 -2809.07920589
M6 	 4 	 0.05 	 -2793.18425379
M7 	 4 	 0.2 	 -2815.45171428
M8 	 4 	 0.05 	 -2799.55676218

Best model is M2
#+end_example

From all the models, the one with the maximal BIC is selected. Then we
plot the results.

#+BEGIN_SRC python 
yp=model.predict(X)

plt.figure()
plt.scatter(Xp[:,0],Xp[:,1],c=yp,s=40)
plt.savefig("2D_hdda.png")
#+END_SRC

#+RESULTS:

[[file:2D_hdda.png]]

The same learning is done with the GMM from scikit, and we plot the results

#+BEGIN_SRC python 
clf = mixture.GMM(n_components=4, covariance_type='full')
clf.fit(X)
yp=clf.predict(X)

plt.figure()
plt.scatter(Xp[:,0],Xp[:,1],c=yp,s=40)
plt.savefig('2D_gmm.png')
#+END_SRC

[[file:2D_gmm.png]]

The complete file is available in [[file:script_crabs.py]].
** Grassland
:PROPERTIES:
:tangle:   script_grasslands.py
:noweb:    yes
:exports:  both
:session:  grassland
:results:  output
:END:
In this example, we show how  HDDA clusterizes pixels from a satellite
image  time series.   Again, we  need  to load  data and  set up  some
parameters.  Then  we use  the  =fit_all=  function  to learn  the  best
model. This  is an example  of the work  of [[mailto:mailys.lopes@toulouse.inra.fr][Ma√Ølys Lopes]]  on grassland
monitoring from satellite image time series.

#+BEGIN_SRC python
import hdda
import scipy as sp
import matplotlib.pyplot as plt
import time as time

# Load data
data = sp.load('prairie5.npy')
x = data
n,d=x.shape
print "Number of samples: {}\n Number of variables: {}".format(n,d)
# Parameters
MODEL = ['M1','M2','M3','M4','M5','M6','M7','M8']
th = [0.05,0.1,0.2]
C = sp.arange(1,5)

# Model Selection
model = hdda.HDGMM()
tic = time.clock()
model.fit_all(x,MODEL=MODEL,C=C,th=th,VERBOSE=True)
toc = time.clock()
print "Processing time: {}".format(toc-tic)
#+END_SRC

#+RESULTS:

#+begin_example

Number of samples: 159
Number of variables: 68
 Models 	 C 	 th 	 BIC
M1 	 4 	 0.05 	 -58257.1815661
M2 	 2 	 0.05 	 -59527.6014904
M3 	 3 	 0.05 	 -58486.9513614
M4 	 2 	 0.05 	 -59696.1778619
M5 	 4 	 0.05 	 -58486.7455612
M6 	 2 	 0.05 	 -59700.561086
M7 	 3 	 0.05 	 -58723.13686
M8 	 2 	 0.05 	 -59901.163825

Best model is M1
Processing time: 17.530738
#+end_example

#+BEGIN_SRC python :exports code
# Plot data
bands= ['B','G','R','NIR']

for i,b in enumerate(bands):
    plt.figure()
    # Plot the samples
    for j in xrange(n):
        plt.plot(data[j,(i*17):((i+1)*17)],'k',lw=0.5)
    # Plot the means
    for j in xrange(len(model.mean)):
        plt.plot(model.mean[j][(i*17):((i+1)*17)],lw=3)
    plt.savefig('grassland_{}.png'.format(b))
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :noweb yes :exports code :tangle no
for b in {B,G,R,NIR}
do
    echo [[file:grassland_$b.png]]
done
#+END_SRC


[[file:grassland_B.png]]
[[file:grassland_G.png]]
[[file:grassland_R.png]]
[[file:grassland_NIR.png]]



